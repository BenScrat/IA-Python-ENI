{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63a45c0e216ae52b",
   "metadata": {},
   "source": [
    "# Les algorithmes de classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ac216a1124f937",
   "metadata": {},
   "source": [
    "## Classification naïve bayésienne (Naive Bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eae2e1268291dd6",
   "metadata": {},
   "source": [
    "L'algorithme Naive Bayes est un classifieur probabiliste basé sur **le théorème de Bayes** et **l'hypothèse d'indépendance des variables**. Il suppose que la présence d'une caractéristique particulière dans une classe donnée est indépendante de la présence de toute autre caractéristique.\n",
    "\n",
    "\n",
    "- **Le théorème de Bayes** est une formule mathématique qui permet de calculer la probabilité d'un événement en fonction de probabilités conditionnelles.\n",
    "\n",
    "\n",
    "- **L'hypothèse d'indépendance des variables** signifie que l'algorithme suppose que les valeurs de chaque attribut sont indépendantes les unes des autres.\n",
    "\n",
    "Relativement simple, il donne souvent de bons résultats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105056882c827c47",
   "metadata": {},
   "source": [
    "Le théorème de Bayes est un résultat fondamental en probabilités qui relie la probabilité conditionnelle d'un événement A sachant un événement B.\n",
    "\n",
    "$$\n",
    "p(Y|X) = \\frac{p(\\text{X}|\\text{Y}) p(\\text{Y})}{p(\\text{X})}\n",
    "$$\n",
    "\n",
    "où :\n",
    "\n",
    "- $p(\\text{Y}|\\text{X})$ est la probabilité conditionnelle de Y sachant X, c'est-à-dire la probabilité que l'événement Y se produise sachant que l'événement X s'est déjà produit.\n",
    "- $p(\\text{X}|\\text{Y})$ est la probabilité conditionnelle de X sachant Y.\n",
    "- $p(\\text{Y})$ est la probabilité que l'événement Y se produise.\n",
    "- $p(\\text{X})$ est la probabilité que l'événement X se produise.\n",
    "\n",
    "Exemple : $p(\\text{« le patient va guérir »}|\\text{« il a pris le médicament »})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4efe62dc4e05da",
   "metadata": {},
   "source": [
    "### Cas des attributs discrets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c54fd30b7c577a",
   "metadata": {},
   "source": [
    "Dans le cas de la classification, nous cherchons à prédire la classe d'un objet en fonction de ses caractéristiques. Nous cherchons donc à calculer la probabilité que l'objet appartienne à une classe donnée sachant ses caractéristiques.\n",
    "\n",
    "Pour plus de clarté, prenons l'exemple suivant. Nous avons un jeu de données de patients avec des informations sur leur taille et le poids, et nous voulons prédire le genre du patient.\n",
    "\n",
    "| Taille | Poids | Genre |\n",
    "| --- | --- | --- |\n",
    "| Grand | Lourd | H |\n",
    "| Grand | Lourd | H |\n",
    "| Petit | Lourd | H |\n",
    "| Grand | Lourd | H |\n",
    "| Petit | Léger | F |\n",
    "| Petit | Lourd | F |\n",
    "| Petit | Léger | F |\n",
    "| Grand | Léger | F |\n",
    "\n",
    "Un nouveau patient arrive, il est grand et lourd. Nous voulons prédire son genre. On a les caractéristiques $X = [\\text{Taille} = \\text{\"Petit\"}, \\text{Poids} = \\text{\"Lourd\"}]$. On va calculer les probabilités que le patient soit un homme et une femme ($p(\\text{F}|\\text{X})$ et $p(\\text{H}|\\text{X})$) et on va choisir la classe avec la probabilité la plus élevée pour ce nouveau patient. Commençons par calculer la probabilité $p(\\text{F}|\\text{X})$.\n",
    "\n",
    "En se basant sur le théorème de Bayes, on a besoin de calculer $p(\\text{X}|\\text{F})$ où $X = \\{x_{1} = \\text{\"Petit\"}, x_{2} = \\text{\"Lourd\"}\\}$. C'est à ce moment que **l'hypothèse d'indépendance des variables** intervient. On suppose que la taille et le poids sont indépendants.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p(\\text{X}|\\text{F}) &= p(\\text{Taille} = \\text{\"Petit\"}|\\text{F}) \\times p(\\text{Poids} = \\text{\"Lourd\"}|\\text{F}) \\\\\n",
    "&= \\frac{3}{4} \\times \\frac{1}{4} \\\\ \n",
    "&= \\frac{3}{16}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "On a $p(\\text{F}) = \\frac{1}{2}$ et pour $p(\\text{X})$ on utilise de nouveau **l'hypothèse d'indépendance des variables**.\n",
    "$$\n",
    "\\begin{align}\n",
    "p(\\text{X}) &= p(\\text{Taille} = \\text{\"Petit\"}) \\times p(\\text{Poids} = \\text{\"Lourd\"}) \\\\\n",
    "&= \\frac{4}{8} \\times \\frac{4}{8} \\\\\n",
    "&= \\frac{1}{2}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "On peut finalement calculer $p(\\text{F}|\\text{X})$.\n",
    "\n",
    "$$\n",
    "p(\\text{F}|\\text{X}) = \\frac{p(\\text{X}|\\text{F}) \\times p(\\text{F})}{p(\\text{X})} = \\frac{\\frac{3}{16} \\times \\frac{1}{2}}{\\frac{1}{2}} = \\frac{3}{16}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a37a857bcb8950",
   "metadata": {},
   "source": [
    "### Cas des attributs continus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1128c1fe075ae01",
   "metadata": {},
   "source": [
    "Estimer les probabilités sur des attributs continus est plus complexe. Il y a alors deux possibilités.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4efd733cc8c11f1",
   "metadata": {},
   "source": [
    "\n",
    "- **Discrétisation des attributs continus** : on peut discrétiser les attributs continus en attributs discrets.\n",
    "\n",
    "| Taille |\n",
    "| --- |\n",
    "| 1.84 |\n",
    "| 1.58 |\n",
    "| 1.47 |\n",
    "| 1.79 |\n",
    "\n",
    "On peut discrétiser les valeurs en utilisant des seuils. Les valeurs deviennent alors les suivantes.\n",
    "\n",
    "\n",
    "| Taille |\n",
    "|--------|\n",
    "| Grand  |\n",
    "| Petit  |\n",
    "| Petit  |\n",
    "| Grand  |\n",
    "\n",
    "une fois la discrétisation effectuée, on peut appliquer la méthode précédente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4b059505d3941d",
   "metadata": {},
   "source": [
    "\n",
    "- **Utilisation de la distribution normale** : on peut supposer que les attributs continus suivent une distribution normale (Gaussienne). On calcule alors la moyenne et l'écart-type de la distribution et on peut ainsi en déduire la probabilité d'une valeur donnée.\n",
    "\n",
    "Formule de la distribution normale :\n",
    "$$\n",
    "p(x_{i}|\\text{Y}) = \\frac{1}{\\sqrt{2\\pi\\sigma}} e^{-\\frac{(x_{i} - \\mu)^{2}}{2\\sigma}}\n",
    "$$\n",
    "\n",
    "Distribution normale.\n",
    "<img src=\"images/01-gaussian-distribution.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6978b28ad5716c5",
   "metadata": {},
   "source": [
    "En résumé, l’algorithme Naive Bayes :\n",
    "- Fonctionne sur un principe simple mais efficace dans de nombreux cas\n",
    "- Peut même gérer des attributs avec des valeurs nulles, en les ignorant dans le calcul de probabilité\n",
    "- N’est pas sensible aux anomalies\n",
    "- N’est pas sensible aux attributs inutiles\n",
    "- Ne fonctionne que pour des données qui ne sont pas corrélées\n",
    "- C’est un des rares algorithmes déterministes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c965543e171543c6",
   "metadata": {},
   "source": [
    "### Implémentation avec Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e82685eec02d806",
   "metadata": {},
   "source": [
    "Il existe plusieurs implémentations de l'algorithme Naive Bayes dans sklearn.naive_bayes :\n",
    "\n",
    "https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "\n",
    "- **GaussianNB** : calcul des probabilités basé sur une distribution normale des données\n",
    "\n",
    "- **MultinomialNB** : utile pour classification de textes\n",
    "\n",
    "- **ComplementNB** : variante du précédent, adapté lorsque les classes sont inégales\n",
    "\n",
    "- **BernoulliNB** : comme GaussianDB, mais avec une distribution des données selon la loi de Bernouilli\n",
    "\n",
    "- **CategoricalNB** : adapté lorsque toutes les variables sont catégorielles\n",
    "\n",
    "Les données Iris sont continues, et suivent globalement une distribution normale. Voici une visualisation permettant de s'en assurer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1afab2d156c5628",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T14:14:05.257230Z",
     "start_time": "2024-05-13T14:14:05.255344Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd1810ab929a5b66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T14:14:05.290613Z",
     "start_time": "2024-05-13T14:14:05.288666Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5af8355e4709a699",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T14:14:05.298347Z",
     "start_time": "2024-05-13T14:14:05.296530Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99b7aef367949776",
   "metadata": {},
   "source": [
    "## Méthode des plus proches voisins (K Nearest Neighbors - KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1f4f90c3df2ec6",
   "metadata": {},
   "source": [
    "L'algorithme k-plus proches voisins (KNN) est une méthode de classification supervisée utilisée en apprentissage automatique. Le principe de base de cet algorithme est de classer une nouvelle donnée en fonction des $K$ données les plus proches de celle-ci dans l'espace d'attributs.\n",
    "\n",
    "Pour utiliser l'algorithme KNN, il faut tout d'abord définir la valeur de $K$, qui représente le nombre de voisins à prendre en compte pour la classification. Ensuite, pour chaque nouvelle donnée à classer, on calcule la distance entre cette donnée et toutes les données d'entraînement disponibles. Les $K$ données les plus proches sont alors sélectionnées, et la classe majoritaire parmi ces $K$ voisins est attribuée à la nouvelle donnée."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57ec5190f22ddbf",
   "metadata": {},
   "source": [
    "KNN\n",
    "<img src=\"images/02-knn.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f10d8dee4dda670",
   "metadata": {},
   "source": [
    "Pour utiliser l'algorithme KNN, il est nécessaire de pouvoir calculer une distance entre deux points dans l'espace d'attributs. Les coordonnées des points sont utilisées pour calculer cette distance.\n",
    "\n",
    "| Point | $X_{1}$ | $X_{2}$ |\n",
    "|-------|---------|---------|\n",
    "| 1     | 1       | 5       |\n",
    "| 2     | 2       | 5       |\n",
    "| 3     | 1       | 3       |\n",
    "| 4     | 3       | 4       |\n",
    "| 5     | 4       | 4       |\n",
    "| 6     | 2       | 2       |\n",
    "| 7     | 3       | 2       |\n",
    "| 8     | 4       | 2       |\n",
    "| 9     | 5       | 3       |\n",
    "| 10    | 5       | 1       |\n",
    "| ?     | 3.5     | 3       |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361261bcc4c166e4",
   "metadata": {},
   "source": [
    "Il existe plein de formules pour calculer la distance entre deux points. Soit $A$ un point de coordonnées dans un espace à $N$ dimension tel que $A = \\{a_{1} , a_{2}, \\ldots , a_{N}$\\} et $B$ un point de coordonnées dans le même espace tel quel $B = \\{b_{1} , b_{2} , \\ldots , b_{n}\\}$.\n",
    "\n",
    "- Distance de Manhattan :\n",
    "\n",
    "$$\n",
    "d(A, B) = \\sum_{i=1}^{N} |a_{i} - b_{i}|\n",
    "$$\n",
    "\n",
    "- Distance euclidienne (dimension 2) :\n",
    "\n",
    "$$\n",
    "d(A, B) = \\sqrt{\\sum_{i=1}^{N} (a_{i} - b_{i})^{2}}\n",
    "$$\n",
    "\n",
    "- Distance de Minkowski (dimension $p$) :\n",
    "\n",
    "$$\n",
    "d(A, B) = \\left( \\sum_{i=1}^{N} |a_{i} - b_{i}|^{p} \\right)^{\\frac{1}{p}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589595dcf7015458",
   "metadata": {},
   "source": [
    "Sur ces calculs de distance, la normalisation des données est souvent cruciale, sinon une donnée avec de grandes valeurs prend bien plus d’importance dans le\n",
    "calcul, par rapport aux autres données."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2733234ba8ea168e",
   "metadata": {},
   "source": [
    "On peut alors construire une matrice symétrique des distances entre chaque point. Si on prend l'exemple des points ci-dessus et qu'on utilise la distance euclidienne, on obtient la matrice suivante."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca28054359299a9a",
   "metadata": {},
   "source": [
    "Matrice de distance euclidienne\n",
    "<img src=\"images/03-euclidian-distance-matrix.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60b748fc69fe2e2",
   "metadata": {},
   "source": [
    "La majorité des 5 plus proches voisins ($K = 5$) appartient à la classe A, donc le point ? est classé dans la classe A."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88dcbe13ec7aac3",
   "metadata": {},
   "source": [
    "Le choix de la valeur de k dans l'algorithme des $K$ plus proches voisins (KNN) est crucial pour obtenir de bons résultats. Si $K$ est trop petit, l'algorithme sera sensible au bruit dans les données, ce qui peut entraîner des erreurs de classification. D'autre part, si $K$ est trop grand, le voisinage ne sera pas représentatif des données locales, ce qui peut également entraîner des erreurs.\n",
    "\n",
    "Pour déterminer la valeur optimale de $K$, on utilise généralement une méthode d'essai et d'erreur en évaluant les performances de l'algorithme pour différentes valeurs de $K$ et en choisissant celle qui minimise l'erreur de classification. Cette approche est similaire à celle utilisée pour d'autres algorithmes d'apprentissage automatique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b321ebc03db748f",
   "metadata": {},
   "source": [
    "### Implémentation avec Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23aae718d2999519",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T14:14:05.301847Z",
     "start_time": "2024-05-13T14:14:05.299944Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.236068</td>\n",
       "      <td>3.162278</td>\n",
       "      <td>3.162278</td>\n",
       "      <td>3.605551</td>\n",
       "      <td>4.242641</td>\n",
       "      <td>4.472136</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>3.201562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.236068</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>2.236068</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.162278</td>\n",
       "      <td>3.605551</td>\n",
       "      <td>3.605551</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.236068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.236068</td>\n",
       "      <td>3.162278</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>2.236068</td>\n",
       "      <td>3.162278</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.472136</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.236068</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>2.236068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.236068</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.236068</td>\n",
       "      <td>2.236068</td>\n",
       "      <td>3.605551</td>\n",
       "      <td>1.118034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.162278</td>\n",
       "      <td>2.236068</td>\n",
       "      <td>3.162278</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>2.236068</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.162278</td>\n",
       "      <td>1.118034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.162278</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>2.236068</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.162278</td>\n",
       "      <td>3.162278</td>\n",
       "      <td>1.802776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.605551</td>\n",
       "      <td>3.162278</td>\n",
       "      <td>2.236068</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.236068</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.236068</td>\n",
       "      <td>2.236068</td>\n",
       "      <td>1.118034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.242641</td>\n",
       "      <td>3.605551</td>\n",
       "      <td>3.162278</td>\n",
       "      <td>2.236068</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.118034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.472136</td>\n",
       "      <td>3.605551</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.236068</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3.162278</td>\n",
       "      <td>2.236068</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.656854</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.472136</td>\n",
       "      <td>3.605551</td>\n",
       "      <td>3.162278</td>\n",
       "      <td>3.162278</td>\n",
       "      <td>2.236068</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.201562</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.118034</td>\n",
       "      <td>1.118034</td>\n",
       "      <td>1.802776</td>\n",
       "      <td>1.118034</td>\n",
       "      <td>1.118034</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0   0.000000  1.000000  2.000000  2.236068  3.162278  3.162278  3.605551   \n",
       "1   1.000000  0.000000  2.236068  1.414214  2.236068  3.000000  3.162278   \n",
       "2   2.000000  2.236068  0.000000  2.236068  3.162278  1.414214  2.236068   \n",
       "3   2.236068  1.414214  2.236068  0.000000  1.000000  2.236068  2.000000   \n",
       "4   3.162278  2.236068  3.162278  1.000000  0.000000  2.828427  2.236068   \n",
       "5   3.162278  3.000000  1.414214  2.236068  2.828427  0.000000  1.000000   \n",
       "6   3.605551  3.162278  2.236068  2.000000  2.236068  1.000000  0.000000   \n",
       "7   4.242641  3.605551  3.162278  2.236068  2.000000  2.000000  1.000000   \n",
       "8   4.472136  3.605551  4.000000  2.236068  1.414214  3.162278  2.236068   \n",
       "9   5.656854  5.000000  4.472136  3.605551  3.162278  3.162278  2.236068   \n",
       "10  3.201562  2.500000  2.500000  1.118034  1.118034  1.802776  1.118034   \n",
       "\n",
       "          7         8         9         10  \n",
       "0   4.242641  4.472136  5.656854  3.201562  \n",
       "1   3.605551  3.605551  5.000000  2.500000  \n",
       "2   3.162278  4.000000  4.472136  2.500000  \n",
       "3   2.236068  2.236068  3.605551  1.118034  \n",
       "4   2.000000  1.414214  3.162278  1.118034  \n",
       "5   2.000000  3.162278  3.162278  1.802776  \n",
       "6   1.000000  2.236068  2.236068  1.118034  \n",
       "7   0.000000  1.414214  1.414214  1.118034  \n",
       "8   1.414214  0.000000  2.000000  1.500000  \n",
       "9   1.414214  2.000000  0.000000  2.500000  \n",
       "10  1.118034  1.500000  2.500000  0.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "import pandas as pd\n",
    "\n",
    "# On définit un nombre de points\n",
    "X = [[1,5],[2,5],[1,3],[3,4],[4,4],[2,2],[3,2],[4,2],[5,3],[5,1],[3.5,3]]\n",
    "\n",
    "# On calcule la matrice des distances\n",
    "matrix_distances = pd.DataFrame(pairwise_distances(X))\n",
    "matrix_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65c761db4d0b34a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T14:14:05.304537Z",
     "start_time": "2024-05-13T14:14:05.303011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Création d'un modèle KNN\n",
    "# La distance euclidienne est la distance de Minkowski dans un espace à 2 dimensions\n",
    "knn = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)\n",
    "\n",
    "# On entraîne le modèle avec les données Iris\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# On affiche la métrique `Accuracy`\n",
    "print(\"Accuracy :\", knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1be27154d3263d",
   "metadata": {},
   "source": [
    "En résumé, KNN :\n",
    "- Fonctionne sur un principe intuitif\n",
    "- Nécessite peu de paramètres\n",
    "- Peut-être couteux en temps de calcul en raison de la matrice des distances\n",
    "- Est très sensible aux plages de données des différents attributs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bca974b557f583a",
   "metadata": {},
   "source": [
    "## Machines à vecteurs de support (Support Vector Machine - SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9841cdabd91fa1",
   "metadata": {},
   "source": [
    "L'algorithme SVM (Support Vector Machine) est utilisé pour la classification de données. Son objectif est de trouver un hyperplan qui sépare au mieux les deux classes. Dans un espace à deux dimensions, cet hyperplan est simplement une droite qui sépare les points des deux classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229e55b73cd2ad7e",
   "metadata": {},
   "source": [
    "Exemples d'hyperplans pour un jeu de données.\n",
    "\n",
    "<img src=\"images/04-svm.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce3c1a17d43f70b",
   "metadata": {},
   "source": [
    "On voit qu'il existe de nombreuses possibilités pour les hyperplans. Pour choisir le meilleur, nous allons sélectionner celui qui maximise les marges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a34aec0c27ce6d",
   "metadata": {},
   "source": [
    "Maximisation des marges.\n",
    "\n",
    "<img src=\"images/05-maximized-hyperplans.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fe73d21cfebca6",
   "metadata": {},
   "source": [
    "Le choix de l’hyperplan qui maximise les marges est un problème d’optimisation sous contraintes, sa résolution est au-delà des attendus de ce cours.\n",
    "\n",
    "Pour classer un nouveau point à l'aide d'un algorithme SVM, une fois que l'hyperplan séparateur a été déterminé, il suffit de vérifier de quel côté de l'hyperplan se trouve le nouveau point. Si le point est du même côté que les points positifs de l'ensemble d'entraînement, il est classé comme positif. S'il est du même côté que les points négatifs, il est classé comme négatif.\n",
    "\n",
    "Toutes les données ne sont pas linéairement séparables, c'est-à-dire qu'il n'existe pas d'hyperplan qui puisse séparer parfaitement les deux classes. Dans ce cas, l'algorithme SVM utilise une fonction de noyau (kernel) pour transformer les données dans un espace de dimension supérieure où elles deviennent linéairement séparables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c659fe6d0bfa537",
   "metadata": {},
   "source": [
    "En résumé, SVM :\n",
    "- Est une résolution d’un problème d’optimisation\n",
    "- Est un algorithme efficace\n",
    "- N’est pas perturbé par les anomalies\n",
    "- A peu de risques de surapprentissage\n",
    "- N’est pas sensible aux données corrélées\n",
    "- N’est pas adapté en cas de données manquantes\n",
    "- Est plus adapté pour les attributs continus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e616d742b28c2a0",
   "metadata": {},
   "source": [
    "### Implémentation avec Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d9cf997f3158f2",
   "metadata": {},
   "source": [
    "Il existe de nombreuses implémentations de SVM avec Scikit-learn. Pour la classification, l’algorithme Support Vector Classification est adapté, et permet de\n",
    "varier les noyaux utilisés pour s’adapter aux différentes données. Pour en savoir plus sur les différents types de noyau, il faut se référer à la documentation de Scikit-learn.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "196a749bcee552a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T14:14:05.310154Z",
     "start_time": "2024-05-13T14:14:05.308339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9466666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "print(\"Accuracy :\", svm.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720bddb4e7f70ebe",
   "metadata": {},
   "source": [
    "## Les réseaux de neurones (Artificial Neural Networks - ANN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdb524e5ebcc640",
   "metadata": {},
   "source": [
    "Les réseaux de neurones sont une classe d'algorithmes d'apprentissage automatique inspirés par l'architecture et le fonctionnement du cerveau humain. Ils sont composés de nombreux neurones artificiels interconnectés, qui fonctionnent ensemble pour traiter des informations complexes.\n",
    "\n",
    "Lorsqu'une information arrive dans le réseau, elle est transmise à travers les connexions entre les neurones, déclenchant ou non leur activation. Les neurones activés envoient ensuite des signaux à d'autres neurones, créant ainsi un réseau complexe de traitement de l'information\n",
    "\n",
    "Les réseaux de neurones sont très utilisés dans de nombreuses applications, telles que la reconnaissance d'images, la reconnaissance vocale, la traduction automatique, et bien d'autres encore. Ils sont capables d'apprendre à partir de grandes quantités de données et de généraliser leurs connaissances à de nouvelles données. Cependant, leur entraînement peut être très coûteux en termes de temps et de ressources informatiques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665d5a1e3d58702e",
   "metadata": {},
   "source": [
    "L'idée sous-jacente de l’algorithme est de créer une fonction complexe non-linéaire, en combinant plusieurs unités de calcul simple appelées neurones.\n",
    "Les réseaux de neurones sont constitués de plusieurs composants principaux.\n",
    "\n",
    "- Les **neurones** qui correspondent aux unités de calculs\n",
    "- Les **connexions** entre les neurones qui transmettent et propagent un signal\n",
    "- Le **poids** de chaque connexion qui traduisent la force et l’importance de la connexion\n",
    "\n",
    "La structure la plus simple du réseau de neurone est le **perceptron**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b842f403aa81dca5",
   "metadata": {},
   "source": [
    "### Le perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399b4fe949ed1cf9",
   "metadata": {},
   "source": [
    "Le perceptron.\n",
    "\n",
    "<img src=\"images/06-perceptron.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8299781c8a89492",
   "metadata": {},
   "source": [
    "Il y a trois étapes majeures dans le fonctionnement d’un perceptron.\n",
    "\n",
    "1. **Pondération des valeurs** : Les valeurs en entrées sont pondérées par des poids, qui seront appris par le modèle.\n",
    "2. **Fonction de combinaison** : Toutes les valeurs calculées dans l'étape 1 sont sommées. \n",
    "$$\n",
    "c = w_{1}x_{1} + w_{2}x_{2} + w_{3}x_{3} + \\ldots + w_{n}x_{n}$\n",
    "$$\n",
    "3. **Fonction d'activation** : Déclenche ou non un signal en fonction du résultat de la fonction de combinaison.\n",
    "\n",
    "Il existe plusieurs fonctions d'activation. Pour ce cours, nous prendrons la fonction suivante.\n",
    "\n",
    "$$\n",
    "\\phi(c) = \\left\\{\n",
    "    \\begin{array}{ll}\n",
    "        1 & \\mbox{si } c \\gt 0 \\\\\n",
    "        -1 & \\mbox{sinon}\n",
    "    \\end{array}\n",
    "\\right\\}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7f6c180fb29985",
   "metadata": {},
   "source": [
    "Le processus d'apprentissage du perceptron est itératif et se déroule en plusieurs étapes :\n",
    "\n",
    "1. **Initialisation** : les poids des connexions entre les neurones sont initialisés à des valeurs aléatoires.\n",
    "\n",
    "$$\n",
    "(w_{1}, w_{2}, \\ldots, w_{n})\n",
    "$$\n",
    "\n",
    "2. **Prédiction** : le perceptron calcule la sortie pour chaque exemple d'entraînement en utilisant les poids actuels. Pour chaque donnée du jeu d'entraînement $(X_{i}, y_{i})$ on calcule la valeur prédite $\\hat{y_{i}}$\n",
    "3. **Mise à jour des poids** : si la prédiction est incorrecte, les poids des connexions sont ajustés en fonction de l'erreur de prédiction.\n",
    "\n",
    "$$\n",
    "w_{j}^{(k+1)} = w_{j}^{k} + \\lambda(y_{i} - \\hat{y_{i}}^{k})x_{ij}\n",
    "$$\n",
    "\n",
    "Où $k$ représente le numéro de l'itération, $j$ est le numéro du poids à ajuster, $\\lambda$ est le taux d'apprentissage et $x_{ij}$ représente la valeur sur la $j$-ème valeur en entrée du neuron ($j$-ème coordonnée de $X_{i}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e066911e1a5fc2",
   "metadata": {},
   "source": [
    "Quelle est l'intuition derrière la mise à jour des poids ? L'idée est de mettre à jour le nouveau poids en fonction de la prédiction.\n",
    "1. S'il n'y a pas d'erreur, le poids reste le même. \n",
    "$$\n",
    "y_{i} = \\hat{y_{i}} \\qquad \\Rightarrow \\qquad w_{j}^{(k+1)} = w_{j}^{k}\n",
    "$$\n",
    "2. Si la valeur d'entraînement est supérieur à la valeur prédite ($y_{i} > \\hat{y_{i}}$), on augmente le poids pour augmenter le poids et se rapprocher de la valuer réelle.\n",
    "3. Si la valeur d'entraînement est inférieur à la valeur prédite ($y_{i} < \\hat{y_{i}}$), on diminue le poids pour diminuer la valeur prédite.\n",
    "\n",
    "C'est ce qu'on appelle la **rétropropagation de l'erreur**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c823028f9af290",
   "metadata": {},
   "source": [
    "Exemple de calcul des poids.\n",
    "\n",
    "<img src=\"images/07-weights.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec45abbd15a34b29",
   "metadata": {},
   "source": [
    "#### Le taux d'apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e018db8efc24fc",
   "metadata": {},
   "source": [
    "Le taux d'apprentissage $\\lambda$ est un paramètre essentiel du calcul du poids.\n",
    "1. Il permet de gérer l'amplitude de mise à jour des poids\n",
    "2. Il a pour objectif de permettre de converger vers un réseau idéal\n",
    "3. Il est un paramètre très important à régler, car il peut avoir un fort impact sur les performances du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb34eb2c61eeb1a",
   "metadata": {},
   "source": [
    "Le taux de convergence.\n",
    "\n",
    "<img src=\"images/08-learning-rate.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85af500e8ea6dc5c",
   "metadata": {},
   "source": [
    "#### Les fonctions d'activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9c0ee9428780bb",
   "metadata": {},
   "source": [
    "Il existe de nombreuses fonctions d'activation différentes. Pour le perceptron, nous avons utilisé une fonction d'activation signe qui renvoie 1 si la somme des entrées pondérées est supérieure à 0, et -1 sinon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a24fad5dcdda1c",
   "metadata": {},
   "source": [
    "Les différentes fonctions d'activation.\n",
    "\n",
    "<img src=\"images/09-activation-function.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b27062f489bf235",
   "metadata": {},
   "source": [
    "### Les réseaux de neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2495893fdb0593a1",
   "metadata": {},
   "source": [
    "Les réseaux de neurones multicouches (ou réseaux de neurones profonds) sont une extension des réseaux de neurones simples, tels que le perceptron. Ils sont composés de plusieurs couches de neurones, chacune prenant ses entrées sur les sorties de la précédente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eac10f1d526d3ac",
   "metadata": {},
   "source": [
    "Les réseaux de neurones. Un rond vert représente un neurone.\n",
    "\n",
    "<img src=\"images/10-neural-network.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea3a9b5b0d935a7",
   "metadata": {},
   "source": [
    "#### La rétropropagation de l'erreur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95862781ee7e1d17",
   "metadata": {},
   "source": [
    "Pour propager l'erreur finale en sortie aux différents poids des couches cachées, on utilise la méthode de rétropropagation de l'erreur. Cette méthode consiste à remonter dans les couches du réseau de neurones, à partir de la sortie. La rétropropagation de l'erreur utilise la méthode de descente du gradient pour ajuster les poids des connexions entre les neurones. Cette méthode consiste à itérer sur les poids en utilisant la dérivée partielle de l'erreur par rapport à chaque poids pour déterminer la direction de la mise à jour. Les poids sont alors ajustés dans la direction opposée à la dérivée partielle pour minimiser l'erreur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2cb4290c6dcdb3",
   "metadata": {},
   "source": [
    "La rétropropagation de l'erreur.\n",
    "\n",
    "<img src=\"images/11-retropropagation.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed2d96ca4815a47",
   "metadata": {},
   "source": [
    "#### L'architecture des réseaux de neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aef1686f506a528",
   "metadata": {},
   "source": [
    "Lors de la création d'un réseau de neurones, il y a plusieurs choix à faire pour définir son architecture. Tout d'abord, le **nombre d'entrées** dépend du nombre d'attributs dans les données d'entrainement. Pour chaque attribut binaire ou continu, il y aura une entrée correspondante. Pour un attribut catégoriel avec $k$ valeurs possibles, il y aura $k$ entrées correspondantes.\n",
    "\n",
    "Ensuite, le **nombre de sorties** dépend du type de problème à résoudre. Dans le cas d'une classification binaire, il n'y aura qu'une seule sortie. Dans le cas d'une classification multiclasse, il y aura autant de sorties que de classes à prédire.\n",
    "\n",
    "Le **nombre de couches cachées** et le nombre de neurones par couche sont des choix importants qui dépendent de la complexité du problème à résoudre. Plus il y a de couches et de neurones, plus le réseau sera capable de modéliser des relations complexes entre les données d'entrée et de sortie, mais plus il sera long à entrainer et plus il risque de sur-apprendre les données d'entrainement.\n",
    "\n",
    "Enfin, il y a plusieurs paramètres à régler pour l'algorithme d'apprentissage, tels que le **taux d'apprentissage** et le **nombre d'itérations**. Ces paramètres peuvent avoir un impact important sur les performances du réseau de neurones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130a1639ff4888f9",
   "metadata": {},
   "source": [
    "#### Le deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e906b2c16139379d",
   "metadata": {},
   "source": [
    "La technique d'apprentissage automatisée la plus mise en avant ces derniers est le **deep learning**. C'est une technique qui utilise des réseaux de neurones avec au moins 5 à 10 couches cachées. Cette méthode nécessite une grande puissance de calcul et des jeux de données importants pour obtenir des résultats précis.\n",
    "\n",
    "Une tendance actuelle dans le domaine du deep learning est l'utilisation de **réseaux pré-entraînés**. Cette approche consiste à entraîner un réseau sur une tâche spécifique, puis à utiliser ce réseau entraîné comme base pour une autre tâche. Cela permet de gagner du temps et d'améliorer les performances, car il n'est plus nécessaire de d'entraîner à nouveau le réseau à partir de zéro pour chaque nouvelle tâche."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dc1e40857c9530",
   "metadata": {},
   "source": [
    "#### Les familles de réseaux de neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea7531aff16ea37",
   "metadata": {},
   "source": [
    "Le domaine des réseaux de neurones est vaste et comprend plusieurs types de réseaux spécialisés pour différents types de tâches. \n",
    "\n",
    "1. Les **réseaux à convolution** sont couramment utilisés pour le traitement d'images et de vidéos. \n",
    "2. Les **réseaux récurrents** sont utilisés pour traiter des séquences, comme dans le cas du traitement du langage naturel. \n",
    "3. Les **auto-encodeurs** sont utilisés pour l'apprentissage non supervisé de caractéristiques à partir de données non étiquetées. \n",
    "4. Les **réseaux LSTM** (Long Short-Term Memory) sont un type de réseau récurrent qui est capable de mémoriser des informations sur de longues séquences. \n",
    "\n",
    "Il existe encore de nombreux autres types de réseaux de neurones, chacun avec ses propres avantages et inconvénients, et leur utilisation dépend de la tâche spécifique à accomplir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31219df7c83e90c",
   "metadata": {},
   "source": [
    "### Implémentation avec Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e04c55cad63988",
   "metadata": {},
   "source": [
    "La classe `MLPClassifier` de Scikit-learn permet de créer un réseau de neurones multicouches pour la classification. Il est possible de régler de nombreux paramètres pour personnaliser le réseau, tels que le nombre de couches cachées, le nombre de neurones par couche, le taux d'apprentissage, le nombre d'itérations, etc. Pour plus d'informations sur les paramètres disponibles, il faut se référer à la documentation de Scikit-learn.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dace4915a83bcbc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T14:14:05.325752Z",
     "start_time": "2024-05-13T14:14:05.323990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "ann = MLPClassifier(max_iter=1000)\n",
    "ann.fit(X_train, y_train)\n",
    "print(\"Accuracy :\", ann.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dba49d94a4bebc8",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8964c88da52cfaa9",
   "metadata": {},
   "source": [
    "- Il existe de très nombreux algorithmes de classification\n",
    "- Ils ont chacun leur forces et faiblesses, et cas d’usages plus adaptés\n",
    "- Vous en avez découvert 4 parmi les plus connus\n",
    "- Les réseaux de neurones sont très utilisés et performants, il faudrait des semaines entières pour tout en découvrir."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
