{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6c97ebc",
   "metadata": {},
   "source": [
    "# TP1 du module 7 : l'apprentissage non supervisé\n",
    "\n",
    "Dans ce TP, nous allons mettre en pratique les principes de l'apprentissage non supervisé. Objectifs :\n",
    "* Passer en revue les principaux algorithmes de clustering\n",
    "* Comparer les performances de ces différents algorithmes\n",
    "* Comparer avec les performances de la classification supervisée.\n",
    "\n",
    "La recherche d'itemsets fréquents et de règles d'associaion ne sera pas abordée dans ce TP."
   ]
  },
  {
   "cell_type": "code",
   "id": "3d02d7de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:03:01.835446Z",
     "start_time": "2024-05-29T13:03:01.832753Z"
    }
   },
   "source": "",
   "execution_count": 68,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "925311c6",
   "metadata": {},
   "source": [
    "Même si ce module concerne l'apprentissage non supervisé, nous allons continuer à explorer le jeu de données du Titanic : cela nous permettra, à la fin, de comparer les clusters obtenus, avec les deux classes réelles obtenus via les labels du jeu de données.\n",
    "\n",
    "Nous allons donc commencer par charger les données. Pour cela, repartez du csv obtenu à la fin du TP1 du module 4. Construisez, comme pour l'apprentissage supervisé, deux dataframe : un avec les attributs, l'autre avec les labels."
   ]
  },
  {
   "cell_type": "code",
   "id": "8660a70c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:03:01.913236Z",
     "start_time": "2024-05-29T13:03:01.880321Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "titanic = pd.read_csv(\"Titanic.csv\")\n",
    "\n",
    "X = titanic.drop(['Survived'], axis=1)\n",
    "y = titanic['Survived']\n",
    "X"
   ],
   "execution_count": 69,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7ab5c627",
   "metadata": {},
   "source": [
    "## Découverte de kmeans\n",
    "\n",
    "1. Nous allons commencer par faire un premier clustering avec KMeans. Comme nous connaissons le nombre de clusters à rechercher, créer un modèle avec la classe de scikit-learn, en fixant le nombre de clusters. Appliquez ce clustering aux attributs de titanic, et récupérer dans une liste le numéro du cluster prédit pour chaque donnée."
   ]
  },
  {
   "cell_type": "code",
   "id": "ad5f4f32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:03:02.041905Z",
     "start_time": "2024-05-29T13:03:01.915229Z"
    }
   },
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Création du modèle grâce à la classe KMeans de Scikit-learn\n",
    "kmeans = KMeans(n_clusters=2, n_init='auto')\n",
    "\n",
    "# Apprentissage des clusters à partir des données\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Pour chaque point, récupérer le numéro du cluster auquel il est affecté\n",
    "y_kmeans = kmeans.predict(X)\n",
    "\n",
    "y_kmeans"
   ],
   "execution_count": 70,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "23f5200c",
   "metadata": {},
   "source": [
    "2. Quelle est la classe majoritaire dans le premier cluster ? Dans le deuxième cluster ? Affichez une matrice, qui donne pour chaque classe le nombre de fois où elle apparait dans chaque cluster. Qu'observez-vous ?"
   ]
  },
  {
   "cell_type": "code",
   "id": "35da6202",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:03:02.053865Z",
     "start_time": "2024-05-29T13:03:02.045886Z"
    }
   },
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y, y_kmeans)\n",
    "cm"
   ],
   "execution_count": 71,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5b356cb5",
   "metadata": {},
   "source": [
    "3. Faite un pairplot des données du Titanic, en colorant chaque donnée en fonction du cluster auquel elle a été affectée. Remarquez-vous des phénomènes intéressants ?"
   ]
  },
  {
   "cell_type": "code",
   "id": "32bf66f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:03:27.812933Z",
     "start_time": "2024-05-29T13:03:02.054863Z"
    }
   },
   "source": [
    "X['y_kmeans'] = y_kmeans\n",
    "sns.pairplot(X, hue='y_kmeans')"
   ],
   "execution_count": 72,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "20edcaa2",
   "metadata": {},
   "source": [
    "4. Les algorithmes de clustering impliquant des mesures de distances, ils sont très sensibles aux plages de valeurs des différents attributs. Normalisez vos données, et refaites les mêmes étapes que précédemment. Observez-vous une différence ?"
   ]
  },
  {
   "cell_type": "code",
   "id": "ee230dda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:05:03.148353Z",
     "start_time": "2024-05-29T13:05:03.094902Z"
    }
   },
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "X_normalized= normalize(X)\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, n_init='auto')\n",
    "y_kmeans_normalize = kmeans.fit_predict(X_normalized)\n",
    "cm = confusion_matrix(y, y_kmeans_normalize)\n",
    "cm"
   ],
   "execution_count": 77,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "69d9c149",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:05:44.593970Z",
     "start_time": "2024-05-29T13:05:14.353566Z"
    }
   },
   "source": [
    "X_normalize_df= pd.DataFrame(X_normalized)\n",
    "X_normalize_df['y_kmeans_normalize'] = y_kmeans_normalize\n",
    "sns.pairplot(X_normalize_df, hue='y_kmeans_normalize')"
   ],
   "execution_count": 78,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "462ecef1",
   "metadata": {},
   "source": [
    "5. Etudions l'évolution du coefficient de silhouette. Pour k variant de 2 à 10, tracez l'évolution de ce coefficient pour un clustering kmeans appliqué au données normalisées. Le nombre de clusters utilisé au question précédentes vous semble-t'il pertinent ?"
   ]
  },
  {
   "cell_type": "code",
   "id": "3b0c59a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:06:39.902208Z",
     "start_time": "2024-05-29T13:06:38.895949Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "k_values = np.arange(2, 11)\n",
    "\n",
    "silhouette_scores = []\n",
    "\n",
    "for k in k_values:\n",
    "    model = KMeans(n_clusters=k, n_init='auto')\n",
    "    y_results = model.fit_predict(X_normalized)\n",
    "    silhouette = silhouette_score(X_normalized, y_results)\n",
    "    silhouette_scores.append(silhouette)\n",
    "\n",
    "print(\"Le meilleur coefficient \", np.max(silhouette_scores), \" est pour k =\", np.argmax(silhouette_scores) + 2)\n",
    "\n",
    "plt.plot(k_values, silhouette_scores)\n",
    "plt.xticks(k_values)\n",
    "plt.xlabel(\"Nombre clusters (k)\")\n",
    "plt.ylabel(\"Score silhouette\")\n",
    "plt.title(\"Evolution de score de silhouette en fonction du nombre de clusters\")\n",
    "plt.show()"
   ],
   "execution_count": 80,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "08525d4b",
   "metadata": {},
   "source": [
    "## Clustering hiérarchique\n",
    "\n",
    "Pour toute la suite du TP, nous travaillerons avec les données normalisées. \n",
    "\n",
    "1. Créez un modèle de clustering hiérarchique (`AgglomerativeClustering`). En utilisant le coefficient de silhouette, comparez le score obtenu pour deux clusters avec celui obtenu par KMeans sur la section précédente."
   ]
  },
  {
   "cell_type": "code",
   "id": "6c8c8175",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:46:38.065372Z",
     "start_time": "2024-05-29T13:46:38.030208Z"
    }
   },
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "hierarchical = AgglomerativeClustering(n_clusters=2)\n",
    "y_kmeans = hierarchical.fit_predict(X_normalized)\n",
    "print(silhouette_score(X_normalized, y_kmeans))"
   ],
   "execution_count": 82,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7527fa93",
   "metadata": {},
   "source": [
    "2. Représentez graphiquement ce nouveau clustering, à l'aide d'un pairplot. Remarquez-vous des tendances ou des changements intéressants ?"
   ]
  },
  {
   "cell_type": "code",
   "id": "6cb2ad2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:50:31.449434Z",
     "start_time": "2024-05-29T13:50:00.465523Z"
    }
   },
   "source": [
    "X_normalize_df= pd.DataFrame(X_normalized)\n",
    "X_normalize_df['y_kmeans_normalize'] = y_kmeans_normalize\n",
    "sns.pairplot(X_normalize_df, hue='y_kmeans_normalize')"
   ],
   "execution_count": 84,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8305067c",
   "metadata": {},
   "source": "3. Etudiez l'impact du paramètre `linkage` sur les résultats de votre clustering hiérarchique. Pour rappel, ce paramètre désigne la manière dont est calculée la distance entre deux clusters, pour décider lesquels réunir à une itération donnée. construisez un graphique montrant la valeur du coefficient silhouette en fonction de la méthode utilisée."
  },
  {
   "cell_type": "code",
   "id": "5e3fa74f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:56:18.565907Z",
     "start_time": "2024-05-29T13:56:18.240224Z"
    }
   },
   "source": [
    "methods= ('ward', 'complete', 'average', 'single')\n",
    "silhouettes = []\n",
    "\n",
    "for m in methods:\n",
    "    hierarchical = AgglomerativeClustering(n_clusters=2, linkage=m)\n",
    "    y_ac = hierarchical.fit_predict(X_normalized)\n",
    "    silhouettes.append(silhouette_score(X_normalized, y_ac))\n",
    "    \n",
    "fig= plt.subplots(figsize=(15,10))\n",
    "plt.plot(methods, silhouettes)\n",
    "plt.title(\"Evolution du coef \")\n",
    "plt.xlabel('Methode')\n",
    "plt.ylabel('Coef de silhouette')\n",
    "plt.show()"
   ],
   "execution_count": 85,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "34eef8e2",
   "metadata": {},
   "source": [
    "## Comparaison des différents clustering\n",
    "\n",
    "Nous allons à présent comparer les résultats obtenus avec les autres algorithmes de clustering proposés par Scikit-learn. Testez ces différents algorithmes, et calculez à chaque fois le coefficient de slihouette obtenu. Pour les algorithmes qui ne demandent pas de préciser le nombre de clusters à construire, affichez le nombre de clusters déduit par l'algorithme.\n",
    "\n",
    "Présentez une synthèse de vos résultats sous forme d'un tableau et d'un graphique.\n",
    "\n",
    "Liste des algorithmes à prendre en compte : KMeans, DBScan, spectral, affinity_propagation, agglomerativeClustering, OPTICS, BIRCH\n",
    "\n",
    "**Attention :** pour certains algorithmes, vous devrez jouer avec les paramètres à votre disposition pour parvenir à obtenir au moins deux clusters."
   ]
  },
  {
   "cell_type": "code",
   "id": "cd9df865",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T14:12:24.610186Z",
     "start_time": "2024-05-29T14:12:20.358067Z"
    }
   },
   "source": [
    "from sklearn.cluster import DBSCAN, SpectralClustering, AffinityPropagation, OPTICS, Birch\n",
    "\n",
    "algorithms =[\n",
    "    KMeans(n_clusters=2, n_init='auto'),\n",
    "    AgglomerativeClustering(n_clusters=2, linkage='average'),\n",
    "    DBSCAN(eps=0.1),\n",
    "    SpectralClustering(n_clusters=2),\n",
    "    AffinityPropagation(),\n",
    "    OPTICS(),\n",
    "    Birch(n_clusters=2, threshold=0.2)\n",
    "]\n",
    "\n",
    "silhouette_scores = []\n",
    "algorithms_names = ['KMeans','AgglomerativeClustering','DBSCAN','SpectralClustering','AffinityPropagation','OPTICS','Birch']\n",
    "\n",
    "\n",
    "for algo in algorithms:\n",
    "    y_algo = algo.fit_predict(X_normalized)\n",
    "    silhouette_scores.append(silhouette_score(X_normalized, y_algo))\n",
    "  \n",
    "    \n",
    "plt.bar(algorithms_names,silhouette_scores)\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel(\"Algorithmes\")\n",
    "plt.ylabel(\"Score de silhouette\")\n",
    "plt.title(\"Score de silhouette en fonction de l'alogoritmes utiliser\")\n",
    "plt.show()"
   ],
   "execution_count": 98,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
